"""
Python CLI –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ ONNX –º–æ–¥–µ–ª–∏ –≤ TensorRT
–°–æ–≥–ª–∞—Å–Ω–æ Task-2-Training-code.txt - Model production packaging (5 –±–∞–ª–ª–æ–≤)

–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:
    uv run python -m pose.mvp.model_converter
    uv run python -m pose.mvp.model_converter --precision fp32 --opt-batch 16
    uv run python -m pose.mvp.model_converter --config configs/training/lstm.yaml
"""

import argparse
import subprocess
import sys
import traceback
from pathlib import Path
from typing import Optional, Tuple

import torch
from hydra import compose, initialize
from hydra.core.global_hydra import GlobalHydra
from omegaconf import DictConfig, OmegaConf


def get_git_commit_id() -> str:
    """–ü–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—É—â–∏–π git commit id."""
    try:
        commit_id = (
            subprocess.check_output(["git", "rev-parse", "HEAD"], cwd=Path.cwd())
            .decode("ascii")
            .strip()
        )
        return commit_id
    except Exception:
        return "unknown"


def check_tensorrt_installation() -> Tuple[bool, str]:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–∫—É TensorRT –∏ trtexec."""
    try:
        result = subprocess.run(
            ["trtexec", "--version"], capture_output=True, text=True, timeout=10
        )
        if result.returncode == 0:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–µ—Ä—Å–∏—é –∏–∑ –≤—ã–≤–æ–¥–∞
            version_line = result.stdout.split("\n")[0] if result.stdout else "Unknown"
            return True, version_line
        else:
            return False, "trtexec –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
    except (subprocess.TimeoutExpired, FileNotFoundError):
        return False, "trtexec –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ PATH"


def validate_precision(precision: str) -> str:
    """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ–ª–∞–≥–∏ —Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–ª—è trtexec."""
    precision = precision.lower()
    precision_map = {"fp32": "", "fp16": "--fp16", "int8": "--int8"}

    if precision not in precision_map:
        raise ValueError(
            f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {precision}. –î–æ—Å—Ç—É–ø–Ω—ã: {list(precision_map.keys())}"
        )

    return precision_map[precision]


def build_shapes(
    min_batch: int, opt_batch: int, max_batch: int, cfg: DictConfig
) -> Tuple[str, str, str]:
    """–°—Ç—Ä–æ–∏—Ç —Å—Ç—Ä–æ–∫–∏ —Ñ–æ—Ä–º —Ç–µ–Ω–∑–æ—Ä–æ–≤ –¥–ª—è LSTM –º–æ–¥–µ–ª–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏."""
    sequence_length = cfg.training.data.sequence_length
    input_size = cfg.training.data.input_size_per_frame

    min_shape = f"input_sequences:{min_batch}x{sequence_length}x{input_size}"
    opt_shape = f"input_sequences:{opt_batch}x{sequence_length}x{input_size}"
    max_shape = f"input_sequences:{max_batch}x{sequence_length}x{input_size}"

    return min_shape, opt_shape, max_shape


def load_config(config_path: Optional[Path] = None) -> DictConfig:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é —á–µ—Ä–µ–∑ Hydra —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –ø—É—Ç—è–º–∏.
    –°–∫—Ä–∏–ø—Ç –ª–µ–∂–∏—Ç –≤ pose/mvp/, configs –≤ –∫–æ—Ä–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞.
    """
    GlobalHydra.instance().clear()

    if config_path:
        # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –ó–ê–ì–†–£–ó–ö–ê –ö–ê–°–¢–û–ú–ù–û–ì–û –ö–û–ù–§–ò–ì–ê
        # –ï—Å–ª–∏ –ø—É—Ç—å –∞–±—Å–æ–ª—é—Ç–Ω—ã–π, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ –Ω–∞–ø—Ä—è–º—É—é
        if config_path.is_absolute():
            config_dir = str(config_path.parent)
            config_name = config_path.stem
        else:
            # –ï—Å–ª–∏ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π, —Å—Ç—Ä–æ–∏–º –æ—Ç –∫–æ—Ä–Ω—è –ø—Ä–æ–µ–∫—Ç–∞
            # pose/mvp/ -> ../../ –¥–ª—è –≤—ã—Ö–æ–¥–∞ –≤ –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞
            project_root = Path(__file__).parent.parent.parent  # ml-project/
            full_config_path = project_root / config_path
            config_dir = str(full_config_path.parent)
            config_name = full_config_path.stem

        with initialize(config_path=config_dir, version_base="1.1"):
            cfg = compose(config_name=config_name)
    else:
        # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –ó–ê–ì–†–£–ó–ö–ê –î–ï–§–û–õ–¢–ù–û–ì–û –ö–û–ù–§–ò–ì–ê
        # –ü—É—Ç—å –æ—Ç pose/mvp/ –¥–æ configs/ - —ç—Ç–æ ../../configs
        config_path_relative = "../../configs"

        with initialize(config_path=config_path_relative, version_base="1.1"):
            cfg = compose(config_name="config")

    return cfg


def create_sample_data(cfg: DictConfig, output_path: Path, num_samples: int = 10):
    """–°–æ–∑–¥–∞–µ—Ç –ø—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è TensorRT engine —Å–æ–≥–ª–∞—Å–Ω–æ Task-2-Training-code.txt."""
    print(f"üìù –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö: {output_path}")

    sequence_length = cfg.training.data.sequence_length
    input_size = cfg.training.data.input_size_per_frame

    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–ª—É—á–∞–π–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ —Ñ–æ—Ä–º–∞—Ç–µ LSTM (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –∫–∞–∫ –ø–æ—Å–ª–µ StandardScaler)
    sample_data = torch.randn(
        num_samples, sequence_length, input_size, dtype=torch.float32
    )

    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –∫–∞–∫ –ø–æ—Å–ª–µ StandardScaler
    sample_data = torch.clamp(sample_data, -3.0, 3.0)

    # –°–æ–∑–¥–∞–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
    metadata = {
        "batch_size": num_samples,
        "sequence_length": sequence_length,
        "input_size_per_frame": input_size,
        "description": "Sample data for LSTM gait classification TensorRT testing",
        "created_by": "model_converter.py",
        "git_commit": get_git_commit_id(),
        "data_range": [-3.0, 3.0],
        "data_format": "standardized",
    }

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    torch.save({"input_sequences": sample_data, "metadata": metadata}, output_path)

    print(f"‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {num_samples} –ø—Ä–∏–º–µ—Ä–æ–≤ —Ñ–æ—Ä–º—ã {list(sample_data.shape)}")
    return output_path


def convert_onnx_to_tensorrt(
    onnx_path: Path,
    engine_path: Path,
    cfg: DictConfig,
    precision: Optional[str] = None,
    min_batch: Optional[int] = None,
    opt_batch: Optional[int] = None,
    max_batch: Optional[int] = None,
    workspace_size: Optional[int] = None,
    verbose: bool = False,
    benchmark: bool = True,
) -> bool:
    """
    –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç ONNX –º–æ–¥–µ–ª—å –≤ TensorRT engine –∏—Å–ø–æ–ª—å–∑—É—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é.
    """
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        if not onnx_path.exists():
            print(f"‚ùå ONNX —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {onnx_path}")
            return False

        # –°–æ–∑–¥–∞–Ω–∏–µ –≤—ã—Ö–æ–¥–Ω–æ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        engine_path.parent.mkdir(parents=True, exist_ok=True)

        # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        tensorrt_cfg = cfg.training.production.tensorrt

        used_precision = precision or tensorrt_cfg.precision
        used_workspace = workspace_size or tensorrt_cfg.workspace_size
        used_min_batch = min_batch or 1
        used_opt_batch = opt_batch or cfg.training.training.batch_size
        used_max_batch = max_batch or tensorrt_cfg.max_batch_size

        # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏
        precision_flag = validate_precision(used_precision)

        # –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Ñ–æ—Ä–º —Ç–µ–Ω–∑–æ—Ä–æ–≤
        min_shape, opt_shape, max_shape = build_shapes(
            used_min_batch, used_opt_batch, used_max_batch, cfg
        )

        print("=== –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è ONNX –≤ TensorRT ===")
        print(f"üìÅ ONNX –º–æ–¥–µ–ª—å: {onnx_path}")
        print(f"üìÅ TensorRT engine: {engine_path}")
        print(f"‚öôÔ∏è –¢–æ—á–Ω–æ—Å—Ç—å: {used_precision}")
        print(f"üíæ Workspace: {used_workspace}MB")
        print(
            f"üìä Batch —Ä–∞–∑–º–µ—Ä—ã: min={used_min_batch}, opt={used_opt_batch}, max={used_max_batch}"
        )
        print(f"üìê –§–æ—Ä–º—ã —Ç–µ–Ω–∑–æ—Ä–æ–≤:")
        print(f"   –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è: {min_shape}")
        print(f"   –û–ø—Ç–∏–º–∞–ª—å–Ω–∞—è: {opt_shape}")
        print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è: {max_shape}")
        print("=" * 50)

        # –ö–æ–º–∞–Ω–¥–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
        cmd = [
            "trtexec",
            f"--onnx={onnx_path}",
            f"--saveEngine={engine_path}",
            f"--workspace={used_workspace}",
            f"--minShapes={min_shape}",
            f"--optShapes={opt_shape}",
            f"--maxShapes={max_shape}",
            "--buildOnly",
        ]

        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ñ–ª–∞–≥–æ–≤ —Ç–æ—á–Ω–æ—Å—Ç–∏
        if precision_flag:
            cmd.append(precision_flag)

        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ verbose
        if verbose:
            cmd.append("--verbose")

        print("üîÑ –ù–∞—á–∞–ª–æ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏...")
        print(f"üîß –ö–æ–º–∞–Ω–¥–∞: {' '.join(cmd)}")

        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏
        result = subprocess.run(cmd, capture_output=not verbose, text=True)

        if result.returncode == 0:
            print("‚úÖ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–∞–∑–º–µ—Ä–µ
            if engine_path.exists():
                size_mb = engine_path.stat().st_size / 1024 / 1024
                print(f"üìä –†–∞–∑–º–µ—Ä engine: {size_mb:.2f} MB")

                # –ë–µ–Ω—á–º–∞—Ä–∫
                if benchmark:
                    print("\nüöÄ –ó–∞–ø—É—Å–∫ –±–µ–Ω—á–º–∞—Ä–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏...")
                    benchmark_cmd = [
                        "trtexec",
                        f"--loadEngine={engine_path}",
                        f"--batch={used_opt_batch}",
                        "--iterations=100",
                        "--warmUp=10",
                        "--duration=10",
                    ]

                    benchmark_result = subprocess.run(
                        benchmark_cmd, capture_output=True, text=True
                    )
                    if benchmark_result.returncode == 0:
                        print("‚úÖ –ë–µ–Ω—á–º–∞—Ä–∫ –∑–∞–≤–µ—Ä—à–µ–Ω")
                        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫ –∏–∑ –≤—ã–≤–æ–¥–∞
                        for line in benchmark_result.stdout.split("\n"):
                            if "mean" in line.lower() and (
                                "ms" in line.lower() or "throughput" in line.lower()
                            ):
                                print(f"üìà {line.strip()}")
                    else:
                        print("‚ö†Ô∏è –û—à–∏–±–∫–∞ –±–µ–Ω—á–º–∞—Ä–∫–∞ (–Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ)")

                return True
            else:
                print("‚ùå Engine —Ñ–∞–π–ª –Ω–µ —Å–æ–∑–¥–∞–Ω")
                return False
        else:
            print("‚ùå –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏:")
            if not verbose:
                print(result.stderr)
            return False

    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        traceback.print_exc()
        return False


def main():
    """CLI –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ ONNX –≤ TensorRT."""
    parser = argparse.ArgumentParser(
        description="–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è ONNX –º–æ–¥–µ–ª–∏ –≤ TensorRT —Å–æ–≥–ª–∞—Å–Ω–æ Task-2-Training-code.txt",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:

  # –ë–∞–∑–æ–≤–∞—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞)
  uv run python -m pose.mvp.model_converter

  # –ö–∞—Å—Ç–æ–º–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –∏ —Ä–∞–∑–º–µ—Ä—ã
  uv run python -m pose.mvp.model_converter --precision fp32 --opt-batch 16

  # –ö–∞—Å—Ç–æ–º–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥
  uv run python -m pose.mvp.model_converter --config configs/training/lstm.yaml

  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
  uv run python -m pose.mvp.model_converter --precision fp16 --max-batch 128 --workspace-size 2048

  # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è DVC
  uv run python -m pose.mvp.model_converter --create-sample-data
        """,
    )

    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument(
        "--config",
        type=Path,
        default=None,
        help="–ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: configs/config.yaml)",
    )

    parser.add_argument(
        "--onnx-path",
        type=Path,
        default=None,
        help="–ü—É—Ç—å –∫ ONNX —Ñ–∞–π–ª—É (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: models/LSTM/ONNX/lstm_gait_classifier.onnx)",
    )

    parser.add_argument(
        "--engine-path",
        type=Path,
        default=None,
        help="–ü—É—Ç—å –¥–ª—è TensorRT engine (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: models/LSTM/TensorRT/lstm_gait_classifier.engine)",
    )

    # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
    parser.add_argument(
        "--precision",
        choices=["fp32", "fp16", "int8"],
        default=None,
        help="–¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–Ω—Ñ–∏–≥)",
    )

    parser.add_argument(
        "--workspace-size",
        type=int,
        default=None,
        help="–†–∞–∑–º–µ—Ä workspace –≤ MB (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–Ω—Ñ–∏–≥)",
    )

    parser.add_argument(
        "--min-batch",
        type=int,
        default=None,
        help="–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π batch size (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–Ω—Ñ–∏–≥)",
    )

    parser.add_argument(
        "--opt-batch",
        type=int,
        default=None,
        help="–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π batch size (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–Ω—Ñ–∏–≥)",
    )

    parser.add_argument(
        "--max-batch",
        type=int,
        default=None,
        help="–ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π batch size (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –∫–æ–Ω—Ñ–∏–≥)",
    )

    # –û–ø—Ü–∏–∏
    parser.add_argument("--verbose", action="store_true", help="–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥")

    parser.add_argument(
        "--no-benchmark",
        action="store_true",
        help="–ù–µ –∑–∞–ø—É—Å–∫–∞—Ç—å –±–µ–Ω—á–º–∞—Ä–∫ –ø–æ—Å–ª–µ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏",
    )

    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è DVC
    parser.add_argument(
        "--create-sample-data",
        action="store_true",
        help="–°–æ–∑–¥–∞—Ç—å –ø—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–¥–æ–±–∞–≤–∏—Ç—å –≤ DVC)",
    )

    parser.add_argument(
        "--sample-output",
        type=Path,
        default=Path("data/tensorrt_samples/sample_batch_32.pt"),
        help="–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–∏–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö",
    )

    parser.add_argument(
        "--sample-size",
        type=int,
        default=32,
        help="–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –≤ sample –¥–∞–Ω–Ω—ã—Ö",
    )

    args = parser.parse_args()

    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    try:
        print("=== –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ ===")
        cfg = load_config(args.config)
        print(f"üìÅ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {args.config or 'configs/config.yaml'}")
        print(f"‚öôÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞:")
        print(f"   Precision: {cfg.training.production.tensorrt.precision}")
        print(f"   Workspace: {cfg.training.production.tensorrt.workspace_size}MB")
        print(f"   Max batch: {cfg.training.production.tensorrt.max_batch_size}")
        print(
            f"   LSTM: {cfg.training.data.sequence_length}x{cfg.training.data.input_size_per_frame}"
        )
        print("=" * 50)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
        print(f"üí° –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ø—Ä–æ–µ–∫—Ç–∞:")
        print(f"   –°–∫—Ä–∏–ø—Ç: {Path(__file__)}")
        print(f"   Configs: {Path(__file__).parent.parent.parent / 'configs'}")
        traceback.print_exc()
        return 1

    # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï –ü–£–¢–ò –ö –§–ê–ô–õ–ê–ú
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ—Ä–µ–Ω—å –ø—Ä–æ–µ–∫—Ç–∞ –æ—Ç —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏—è —Å–∫—Ä–∏–ø—Ç–∞
    project_root = Path(__file__).parent.parent.parent  # ml-project/

    if args.onnx_path is None:
        onnx_path = project_root / "models/LSTM/ONNX/lstm_gait_classifier.onnx"
    else:
        onnx_path = args.onnx_path
        if not onnx_path.is_absolute():
            onnx_path = project_root / onnx_path

    if args.engine_path is None:
        engine_path = project_root / "models/LSTM/TensorRT/lstm_gait_classifier.engine"
    else:
        engine_path = args.engine_path
        if not engine_path.is_absolute():
            engine_path = project_root / engine_path

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ TensorRT
    tensorrt_available, tensorrt_info = check_tensorrt_installation()
    if not tensorrt_available:
        print(f"‚ùå {tensorrt_info}")
        print("\nüí° –î–ª—è —É—Å—Ç–∞–Ω–æ–≤–∫–∏ TensorRT:")
        print("   1. –°–∫–∞—á–∞–π—Ç–µ TensorRT —Å NVIDIA Developer")
        print("   2. –î–æ–±–∞–≤—å—Ç–µ –≤ PATH: export PATH=$PATH:/path/to/tensorrt/bin")
        print("   3. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ Python –ø–∞–∫–µ—Ç: pip install tensorrt")
        return 1
    else:
        print(f"‚úÖ TensorRT: {tensorrt_info}")

    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö (–µ—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω–æ)
    if args.create_sample_data:
        try:
            sample_output = args.sample_output
            if not sample_output.is_absolute():
                sample_output = project_root / sample_output

            sample_output.parent.mkdir(parents=True, exist_ok=True)
            sample_path = create_sample_data(cfg, sample_output, args.sample_size)
            print(f"\nüí° –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö —Å–æ–∑–¥–∞–Ω: {sample_path}")
            print(f"üì¶ –î–æ–±–∞–≤—å—Ç–µ –≤ DVC:")
            print(f"   dvc add {sample_path.relative_to(project_root)}")
            print(f"   git add {sample_path.relative_to(project_root)}.dvc")
            print(f"   git commit -m 'Add TensorRT sample data'")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–º–µ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return 1

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ ONNX —Ñ–∞–π–ª–∞
    if not onnx_path.exists():
        print(f"‚ùå ONNX —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {onnx_path}")
        print("üí° –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –∏ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–π—Ç–µ –≤ ONNX:")
        print("   uv run python -m pose.mvp.models.LSTM.LSTM")
        return 1

    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è
    success = convert_onnx_to_tensorrt(
        onnx_path=onnx_path,
        engine_path=engine_path,
        cfg=cfg,
        precision=args.precision,
        min_batch=args.min_batch,
        opt_batch=args.opt_batch,
        max_batch=args.max_batch,
        workspace_size=args.workspace_size,
        verbose=args.verbose,
        benchmark=not args.no_benchmark,
    )

    if success:
        print("\nüéØ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        print(f"üìÅ TensorRT engine: {engine_path}")
        print(f"üìä –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {engine_path.stat().st_size / 1024 / 1024:.2f} MB")
        print("\nüí° –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
        print("   1. –î–æ–±–∞–≤—å—Ç–µ engine –≤ .gitignore (–±–æ–ª—å—à–æ–π —Ñ–∞–π–ª)")
        print("   2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ engine –¥–ª—è inference —á–µ—Ä–µ–∑ TensorRT API")
        print("   3. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ production inference server")

        # –ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        print("\nüöÄ –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å:")
        print(
            f"   –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è batch_size={args.opt_batch or cfg.training.training.batch_size}"
        )
        print(
            f"   –¢–æ—á–Ω–æ—Å—Ç—å: {args.precision or cfg.training.production.tensorrt.precision}"
        )
        print(
            f"   –í—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç: [{args.opt_batch or cfg.training.training.batch_size}, {cfg.training.data.sequence_length}, {cfg.training.data.input_size_per_frame}]"
        )

        return 0
    else:
        print("\n‚ùå –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å")
        print("üí° –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ª–æ–≥–∏ –≤—ã—à–µ –∏ –∏—Å–ø—Ä–∞–≤—å—Ç–µ –æ—à–∏–±–∫–∏")
        return 1


if __name__ == "__main__":
    sys.exit(main())
