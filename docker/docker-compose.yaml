services:
  scripts:
    build:
      context: ..
      dockerfile: docker/Dockerfile
    container_name: ml-project-app
    volumes:
      - ../:/ml-project
    ports:
      - "8888:8888"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    stdin_open: true
    tty: true
    command: /bin/bash

  mlflow:
    image: python:3.9-slim
    container_name: ml-project-mlflow
    ports:
      - "8080:5000"
    volumes:
      - mlflow_data:/mlflow
    command: >
      sh -c "pip install mlflow &&
             mlflow server
             --host 0.0.0.0
             --port 5000
             --backend-store-uri /mlflow/mlruns
             --default-artifact-root /mlflow/mlartifacts"
    restart: always

volumes:
  mlflow_data:
