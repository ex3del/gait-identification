# Пайплайн классификации людей на 17 точек

## Полный прогон скриптов:

## Шаг 1: Первоначальная настройка окружения

Этот шаг выполняется **один раз** для подготовки вашего рабочего пространства. Скрипт создаст виртуальное окружение, установит все необходимые зависимости, загрузит данные с помощью DVC и настроит pre-commit хуки.

Откройте терминал в корневой папке проекта и выполните команду, соответствующую вашей операционной системе:

- **Windows (в PowerShell):**

  ```powershell
  .\setup.bat
  ```

- **macOS / Linux:**
  ```bash
  bash setup.sh
  ```

## Шаг 2: Запуск конвейера обучения (Training Pipeline)

Процесс обучения состоит из трех этапов: запуск сервера для отслеживания экспериментов, выполнение самого конвейера и остановка сервера.

### 2.1. Запуск MLflow сервера

Сервер MLflow необходим для логирования метрик, параметров и артефактов ваших экспериментов. Запустите его **в отдельном терминале**.

- **Windows (в PowerShell):**

  ```powershell
  .\mlflow_control.bat start
  ```

- **macOS / Linux:**
  ```bash
  bash mlflow_control.sh start
  ```

### 2.2. Запуск конвейера обучения

В **другом терминале** запустите основной скрипт, который выполнит шаги по обработке признаков (feature baking) и обучению LSTM модели.

- **Windows (в PowerShell):**

  ```powershell
  .\run_pipeline.bat
  ```

- **macOS / Linux:**
  ```bash
  bash run_pipeline.sh
  ```

## Шаг 3: Запуск оценки модели (Inference)

Этот скрипт запускает процесс оценки на основе уже обученной модели.

- **Windows (в PowerShell):**

  ```powershell
  .\evaluate.bat
  ```

- **macOS / Linux:**
  ```bash
  bash evaluate.sh
  ```

### 4 Остановка MLflow сервера

После того как конвейер обучения успешно завершил свою работу, вы можете остановить MLflow сервер.

- **Windows (в PowerShell):**

  ```powershell
  .\mlflow_control.bat stop
  ```

- **macOS / Linux:**
  ```bash
  bash mlflow_control.sh stop
  ```

---

## Справочник: Полный список команд

### Первоначальная настройка (Setup)

```bash
uv venv
source .venv/Scripts/activate
uv pip install -e .
dvc pull
uv sync --group dev
pre-commit install
uv run pre-commit run -a
```

### Запуск MLflow Server

```bash
uv run mlflow server --host 127.0.0.1 --port 8080
```

### Обучение (Train)

```bash
uv run python -m pose.mvp.feature_bake
uv run python -m pose.mvp.feature_bake preprocessing=eval
uv run python -m pose.mvp.models.LSTM.LSTM
```

### Оценка (Inference)

```bash
uv run python -m pose.mvp.models.LSTM.eval
```

---

# Руководство по проекту

---

```bash
LSTM
```

Выполняет полную обработку тренировочных данных, тренирует модель, выводит результаты классификации, сохраняет веса, графики.

```bash
LSTM
```

Выполняет полную обработку валидационных данных, выполняет инференс валидационных данных, выводит уверенность в классе и распределение предсказаний по классам, выводится и сохраняется в .csv classification report.

### Извлечение mp4:

```bash
bag2mp4
```

Скрипт конвертирует `.bag` файл в `.mp4` видео, которое подаётся в yolo.
Если требуется обработка валидационных данных, то нужно поставить флаг
`eval=True` в функции `main`.

### Извлечение 17 точек тела с yolo:

```bash
yolo17
```

Подаём `mp4` видео с предыдущего шага в yolo на инференс 17-ти точек.
На выходе получаем `.txt` файл `(n_frames, 17, 2)`
с координатами пикселей суставных точек. Сохраняется txt файл. (А надо бы `npy`).
Если требуется обработка валидационных данных, то нужно поставить флаг `eval=True`.

### Извлечение 3d-позиций 17 точек:

```bash
get3d
```

Конвертируем `.bag` файл с 3d-координатами и `.txt` файл с предыдущего шага с пикселями в `.npy` с трёхмерными координатами суставных точек. Сохраняется `npy`-файл с `3d` координатами.
Если требуется обработка валидационных данных, то нужно поставить флаг `eval=True`.

### Подготовка признаков для обучения

```bash
get_features
```

Скрипт, который склеивает в один numpy файл длины, углы, производные длин и углов и координаты(если поставить `add_3d_points=True`) и сохраняет его. Лучше не добавлять 3д координаты к данным, сильно захламляют LSTM.
Если требуется обработка валидационных данных, то нужно поставить флаг `eval=True`. Появился 2ой параметризатор (нужно поставить флаг `extractor_2=True`). Принцип его работы описан ниже.

### Обучение моделей:

```bash
LSTM
```

Классификатор ЛСТМ. Трейновая часть + инференс теста.
Сохраняет веса лучшей модели и веса скейлера данных. Сохраняет графики обучения в папку с весами.
Если нужно сохранять несколько графиков, то надо изменить имя файла, иначе просто перезаписывает существующий.
Если вносить 3д координаты, модель ничего не может предсказать на новых данных.

```bash
MLP
```

Классификатор MLP. Трейновая часть + инференс теста.
Сохраняет веса лучшей модели и веса скейлера данных. Сохраняет графики обучения в папку с весами.
Если нужно сохранять несколько графиков, то надо изменить имя файла, иначе просто перезаписывает существующий.
Если вносить 3д координаты, модель ничего не может предсказать на новых данных.

### Инференс валидационных данных:

```bash
LSTM_eval
```

Валидационный скрипт для ЛСТМ. Для использования требует обученную модель. Выполняет обработку валидационных данных.
Выполняет инференс валидационных данных. Выводит уверенность в классе и распределение предсказаний по классам.
В конце выводится и сохраняется в .csv classification report.
Пока отрабатывает 5 из 7 классов. Точность 60%

```bash
Catboost
```

Валидационный скрипт для Catboost. Для использования требует обученную модель. Выполняет обработку валидационных данных.
Выполняет инференс валидационных данных. Выводит уверенность в классе и распределение предсказаний по классам.
В конце выводится и сохраняется в .csv classification report.
Пока отрабатывает 5 из 7 классов. Точность 53% (угадывает 5 из 7 человек)

### Вспомогательные скрипты:

```bash
 vizualization.py
```

Окно визуализации для отлавливания багов. Для запуска нужен файл с 3d координатами и видео mp4. Выводит общее окно, где слева проигрывается mp4 видео, а справа визуализация 3d скелета.

```bash
 plot_builder
```

Строит сетку графиков 84 х 3 с распределением параметров во времени для выбранного человека. Сохраняет pdf файл.
Чтобы отработал, нужно при подготовке данных указать `parametrization=False` в скрипте `feature_bake.py`

## Разбор параметризаторов:

### Выделение прзнаков ходьбы:

- 1. Сначала в параметризатор `feature_bake` подаются воксели ( x y z коррдинаты каждой точки)
- 2. Воксели проходят комплементарный фильтр КФ (экспоненциальное затухание) с `к = 0.007`
- 3. Вычисляются углы, длины между точками. Всего 12 соединений. на выходе получаем 28 фичей.
- 4. Дифференциируем каждую строку входного массива и считаем длины. Получаем 12 фичей.
- 5. Повторно дифференциируем каждую строку входного массива и считаем длины. Получаем 12 фичей.
- 6. Углы, длины, производные длин проходят комплементарный фильтр КФ(ЭЗ) с `к = 0.05`
- 7. Дважды дифференциируем каждую строку входного массива с углами. И получаем 32 фичи (16 с первой производной углов, 16 со второй)
- 8. Склеиваем все фичи в единый массив и получаем 84 (длины, углы, первая производная длин, первая производная углов, вторая производная длин, вторая производная углов)

### 1ый параметризатор с шириной окна 8 фреймов и прорежением каждого второго фрейма:

- 1. Мы берем 84 фичи и теперь группируем фреймы (с шагом 2) в один большой батч с данными, который содержит в себе информацию о 5 фреймах ~ 270мс (420 фичей-> 0,2,4,6,8 фреймы), делаем шаг и повторяем процедуру. То есть мы обобщаем информацию о нескольких кадрах в один большой сэмпл.

### 2ой параметризатор с шириной окна 30 фреймов и сдвигом 3 фрейма (`extractor_n_frames=True, sliding_window(window_size=30, step=3)`):

- 1. Мы берем 84 фичи и теперь группируем фреймы (с шагом 3) в один большой батч с данными, который содержит в себе информацию о 30 фреймах ~ 1сек (2520 фичей), делаем шаг и повторяем процедуру. То есть мы обобщаем информацию о нескольких кадрах в один большой сэмпл.

### 3ий параметризатор с шириной окна 10 фреймов и сдвигом 5 фрейма (`extractor_n_frames=True, sliding_window(window_size=10, step=5)`):

- 1. Мы берем 84 фичи и теперь группируем фреймы (с шагом 5) в один большой батч с данными, который содержит в себе информацию о 10 фреймах, делаем шаг и повторяем процедуру. То есть мы обобщаем информацию о нескольких кадрах в один большой сэмпл.

### 4ый параметризатор с шириной окна 15 фреймов и сдвигом 7 фрейма (`extractor_n_frames=True, sliding_window(window_size=15, step=7)`):

- 1. Мы берем 84 фичи и теперь группируем фреймы (с шагом 7) в один большой батч с данными, который содержит в себе информацию о 15 фреймах (половина цикла шага), делаем шаг и повторяем процедуру. То есть мы обобщаем информацию о нескольких кадрах в один большой сэмпл.

## Cхема пайплайна:

![Пайплайн](Pipeline_scheme.png)

## Скелет человека

![17 Скелетных точек](yolo_scheme.png)

## Таблица углов между конченостями

| №   | Вершина | Ребро 1 | Ребро 2 |
| --- | ------- | ------- | ------- |
| 1   | 5       | 5–6     | 5–7     |
| 2   | 5       | 5–6     | 5–11    |
| 3   | 5       | 5–7     | 5–11    |
| 4   | 6       | 6–5     | 6–8     |
| 5   | 6       | 6–5     | 6–12    |
| 6   | 6       | 6–8     | 6–12    |
| 7   | 7       | 7–5     | 7–9     |
| 8   | 8       | 8–6     | 8–10    |
| 9   | 11      | 11–5    | 11–12   |
| 10  | 11      | 11–5    | 11–13   |
| 11  | 11      | 11–12   | 11–13   |
| 12  | 12      | 12–6    | 12–11   |
| 13  | 12      | 12–6    | 12–14   |
| 14  | 12      | 12–11   | 12–14   |
| 15  | 13      | 13–11   | 13–15   |
| 16  | 14      | 14–12   | 14–16   |

## Список соединений конечностей

| №   | Соединение |
| --- | ---------- |
| 1   | 15 — 13    |
| 2   | 13 — 11    |
| 3   | 16 — 14    |
| 4   | 14 — 12    |
| 5   | 11 — 12    |
| 6   | 5 — 11     |
| 7   | 6 — 12     |
| 8   | 5 — 6      |
| 9   | 5 — 7      |
| 10  | 6 — 8      |
| 11  | 7 — 9      |
| 12  | 8 — 10     |

## Результаты классификации используя 1ый параметризатор:

| Model                                      | f1 test | f1 validation | detected people validation |
| ------------------------------------------ | ------- | ------------- | -------------------------- |
| **LSTM**                                   | 0.--    | 0.--          | --/19                      |
| **Catboost**                               | 0.--    | 0.--          | --/19                      |
| **LightGBM**                               | 0.--    | 0.--          | --/19                      |
| **MLP_70_hidden_size**                     | 0.--    | 0.--          | --/19                      |
| **Xgboost**                                | 0.--    | 0.--          | --/19                      |
| **MLP_99_hidden_size_55step**              | 0.95    | 0.56          | 10/19                      |
| **MLP_251_81_GELU_shuffled_85step**        | 0.--    | 0.--          | --/19                      |
| **MLP_251_81_hidden_size_Tanh_55step**     | 0.95    | 0.54          | 11/19                      |
| **MLP_99_hidden_size_Tanh_55step**         | 0.--    | 0.--          | --/19                      |
| **MLP_99hs_Tanh_shuffled_stride_3_55step** | 0.--    | 0.--          | --/19                      |
| **MLP_70_hidden_size_Tanh_stride_4**       | 0.--    | 0.--          | --/19                      |
| **MLP_70_hidden_size_Tanh_stride_6**       | 0.--    | 0.--          | -/19                       |

## Результаты классификации используя 2ой параметризатор (для MLP default stride=3):

| Model                                   | f1 test | f1 validation | detected people validation |
| --------------------------------------- | ------- | ------------- | -------------------------- |
| **LSTM_50step**                         | 0.94    | 0.56          | 11/19                      |
| **MLP_99_hidden_size_60step**           | 0.95    | 0.68          | 12/19                      |
| **MLP_251_81_hidden_size**              | 0.--    | 0.--          | --/19                      |
| **MLP_251_81_hidden_size_Tanh_75_step** | 0.94    | 0.61          | 12/19                      |
| **MLP_99_hidden_size_Tanh**             | 0.--    | 0.--          | --/19                      |
| **MLP_70_hidden_size_Tanh_stride_4**    | 0.--    | 0.--          | --/19                      |
| **MLP_70_hidden_size_Tanh_stride_5**    | 0.--    | 0.--          | --/19                      |
| **MLP_70_hidden_size_Tanh_stride_6**    | 0.--    | 0.--          | --/19                      |
| **Catboost**                            | 0.--    | 0.--          | --/19                      |
| **Xgboost**                             | 0.--    | 0.--          | --/19                      |

## Результаты классификации используя параметризатор 3 (Соколовой):

| Model                                          | f1 test | f1 validation | detected people validation |
| ---------------------------------------------- | ------- | ------------- | -------------------------- |
| **LSTM**                                       | 0.--    | 0.--          | --/19                      |
| **Catboost**                                   | 0.--    | 0.--          | --/19                      |
| **LightGBM**                                   | 0.--    | 0.--          | --/19                      |
| **MLP_70_hidden_size**                         | 0.--    | 0.--          | --/19                      |
| **Xgboost**                                    | 0.--    | 0.--          | --/19                      |
| **MLP_99_hidden_size_step_55**                 | 0.94    | 0.62          | 12/19                      |
| **MLP_251_81_hidden_size**                     | 0.--    | 0.--          | --/19                      |
| **MLP_251_81_hidden_size_Tanh_300epochs**      | 0.95    | 0.56          | 12/19                      |
| **MLP_251_81_hidden_size_Tanh_ORIN_300epochs** | 0.95    | 0.53          | 12/19                      |
| **MLP_99_hidden_size_Tanh**                    | 0.--    | 0.--          | -/19                       |
| **MLP_70_hidden_size_Tanh_stride_4**           | 0.--    | 0.--          | --/19                      |
| **MLP_70_hidden_size_Tanh_stride_5**           | 0.--    | 0.--          | --/19                      |
| **MLP_70_hidden_size_Tanh_stride_6**           | 0.--    | 0.--          | -/19                       |

## Результаты классификации используя параметризатор 4(window_size = 15, stride = 7):

| Model                                         | f1 test    | f1 validation | detected people validation |
| --------------------------------------------- | ---------- | ------------- | -------------------------- |
| **LSTM**                                      | 0.90       | 0.69          | 10/19                      |
| **Catboost**                                  | 0.89       | 0.33          | 7/19                       |
| **LightGBM**                                  | 0.88       | 0.25          | 10/19                      |
| **MLP_70_hidden_size**                        | 0.97       | 0.65          | 9/19                       |
| **Xgboost**                                   | 0.89       | 0.26          | 6/19                       |
| **MLP_251_81_hidden_size_Tanh**               | 0.98       | 0.65          | 11/19                      |
| **MLP_99_hidden_size_Tanh**                   | 0.95       | 0.58          | 10/19                      |
| ----------------------                        | ---------- | ---------     | ----------                 |
| **MLP_251_81_hidden_size_Tanh_ws15_stride_5** | 0.96       | 0.69          | 12/19                      |

## Скорость устройств :

| Device                        | data preparation 2 videos | training 26 classes 300 epochs | evaluation 19 classses |
| ----------------------------- | ------------------------- | ------------------------------ | ---------------------- |
| **Nvidia Jetson Orin agx 64** | 85                        | 48                             | 13                     |
| **Nvidia Jetson TX2**         | --                        | 104                            | 34(19 with features)   |
| **A100 40GB**                 | 59                        | 42                             | 11                     |
| **RTX 4070 TI SUPER**         | 39                        | 19                             | 2                      |

## Результаты классификации с использованием обновленного MLP

nn.init.kaiming*normal*

1. Новая модель MLP*512_256_128_64_Gelu с инициализацией весов : nn.init.kaiming_normal*
2. Использование StratifiedKFold cross-validation

| Model                       | f1 test | f1 validation | detected people validation |
| --------------------------- | ------- | ------------- | -------------------------- |
| **MLP_512_256_128_64_Gelu** | 1.00    | 0.47          | 15/21                      |
